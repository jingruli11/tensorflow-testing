{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project\n",
    "\n",
    "Michael Li\n",
    "\n",
    "Dec 10, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import timeit\n",
    "import datetime\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Cleanse Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "mnisttt = input_data.read_data_sets(\".\", one_hot=False, validation_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to plot images\n",
    "def image_plot(image, size):\n",
    "    idxs = np.random.randint(len(image), size=size)\n",
    "    plt.clf()\n",
    "    f, axarr = plt.subplots(1, size, figsize = (20,20))\n",
    "    for i in range(0,len(idxs)):\n",
    "        X = mnisttt.train.images[idxs[i]]\n",
    "        X = X.reshape([28, 28])\n",
    "        axarr[i].imshow(X)\n",
    "        axarr[i].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111b8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAABPCAYAAACd3AICAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHOTlMG0ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126ce0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 20 random images\n",
    "image_plot(mnisttt.train.images, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training image dataset is:  (60000, 784)\n",
      "The size of training label dataset is:  (60000,)\n",
      "The size of validation image dataset is:  (0, 784)\n",
      "The size of validation label dataset is:  (0,)\n",
      "The size of testing image dataset is:  (10000, 784)\n",
      "The size of testing label dataset is:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# print dataset size\n",
    "print('The size of training image dataset is: ', mnisttt.train.images.shape)\n",
    "print('The size of training label dataset is: ', mnisttt.train.labels.shape)\n",
    "print('The size of validation image dataset is: ', mnisttt.validation.images.shape)\n",
    "print('The size of validation label dataset is: ', mnisttt.validation.labels.shape)\n",
    "print('The size of testing image dataset is: ', mnisttt.test.images.shape)\n",
    "print('The size of testing label dataset is: ', mnisttt.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Easy / Hard Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To find the label 'Easy / Hard', 5 classification models will be used:\n",
    "    1. Perceptron\n",
    "    2. Logistic Regression\n",
    "    3. Linear SVM\n",
    "    4. Decision Tree\n",
    "    5. Random Forest\n",
    "\n",
    "\n",
    "- Each classification model will be applied with 2 sets of parameters, which totals up to 10 classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to classify data using Perceptron\n",
    "def clf_perceptron(train_image, train_label, test_image, test_label, p):\n",
    "    clf = Perceptron(n_iter=p)\n",
    "    clf.fit(train_image, train_label)\n",
    "    train_pred = clf.predict(train_image)\n",
    "    test_pred = clf.predict(test_image)\n",
    "    df_train_temp = pd.DataFrame({'Label': train_label, 'Pred': train_pred})\n",
    "    df_test_temp = pd.DataFrame({'Label': test_label, 'Pred': test_pred})\n",
    "    # Correct -> 1, Wrong -> 0\n",
    "    df_train_temp['Perceptron'] = df_train_temp.apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    df_test_temp['Perceptron'] = df_test_temp.apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    return df_train_temp[['Perceptron']], df_test_temp[['Perceptron']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 173.288\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Use perceptron to classify training and testing datasets with n_iter = 75\n",
    "df_p_train1, df_p_test1 = clf_perceptron(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 75)\n",
    "\n",
    "# Use perceptron to classify training and testing datasets with n_iter = 150\n",
    "df_p_train2, df_p_test2 = clf_perceptron(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 150)\n",
    "\n",
    "# rename the dataframes to include parameter\n",
    "df_p_train1.rename(columns = {'Perceptron': 'C1 Perceptron n_iter = 75'}, inplace = True)\n",
    "df_p_test1.rename(columns = {'Perceptron': 'C1 Perceptron n_iter = 75'}, inplace = True)\n",
    "df_p_train2.rename(columns = {'Perceptron': 'C1 Perceptron n_iter = 150'}, inplace = True)\n",
    "df_p_test2.rename(columns = {'Perceptron': 'C1 Perceptron n_iter = 150'}, inplace = True)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to classify data using Logistic Regression\n",
    "def clf_logit(train_image, train_label, test_image, test_label, p):\n",
    "    clf = LogisticRegression(penalty = 'l2', C = p, solver ='newton-cg')\n",
    "    clf.fit(train_image, train_label)\n",
    "    train_pred = clf.predict(train_image)\n",
    "    test_pred = clf.predict(test_image)\n",
    "    df_train_temp = pd.DataFrame({'Label': train_label, 'Pred': train_pred})\n",
    "    df_test_temp = pd.DataFrame({'Label': test_label, 'Pred': test_pred})\n",
    "    # Correct -> 1, Wrong -> 0\n",
    "    df_train_temp['Logit'] = df_train_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    df_test_temp['Logit'] = df_test_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    return df_train_temp[['Logit']], df_test_temp[['Logit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 355.211\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Use Logistic Regression to classify training and testing datasets with C = 0.1\n",
    "df_logit_train1, df_logit_test1 = clf_logit(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 0.1)\n",
    "\n",
    "# Use Logistic Regression to classify training and testing datasets with C = 0.01\n",
    "df_logit_train2, df_logit_test2 = clf_logit(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 0.01)\n",
    "\n",
    "# rename the dataframes to include parameter\n",
    "df_logit_train1.rename(columns = {'Logit': 'C2 Logistic Regression C = 0.1'}, inplace = True)\n",
    "df_logit_test1.rename(columns = {'Logit': 'C2 Logistic Regression C = 0.1'}, inplace = True)\n",
    "df_logit_train2.rename(columns = {'Logit': 'C2 Logistic Regression C = 0.01'}, inplace = True)\n",
    "df_logit_test2.rename(columns = {'Logit': 'C2 Logistic Regression C = 0.01'}, inplace = True)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to classify data using Linear SVM\n",
    "def clf_lsvm(train_image, train_label, test_image, test_label, p):\n",
    "    clf = LinearSVC(penalty = 'l2', C = p, multi_class = 'ovr')\n",
    "    clf.fit(train_image, train_label)\n",
    "    train_pred = clf.predict(train_image)\n",
    "    test_pred = clf.predict(test_image)\n",
    "    df_train_temp = pd.DataFrame({'Label': train_label, 'Pred': train_pred})\n",
    "    df_test_temp = pd.DataFrame({'Label': test_label, 'Pred': test_pred})\n",
    "    # Correct -> 1, Wrong -> 0\n",
    "    df_train_temp['Linear SVM'] = df_train_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    df_test_temp['Linear SVM'] = df_test_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    return df_train_temp[['Linear SVM']], df_test_temp[['Linear SVM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 45.904\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Use Linear SVM to classify training and testing datasets with C = 0.1\n",
    "df_lsvm_train1, df_lsvm_test1 = clf_lsvm(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 0.1)\n",
    "\n",
    "# Use Linear SVM to classify training and testing datasets with C = 0.01\n",
    "df_lsvm_train2, df_lsvm_test2 = clf_lsvm(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 0.01)\n",
    "\n",
    "# rename the dataframes to include parameter\n",
    "df_lsvm_train1.rename(columns = {'Linear SVM': 'C3 Linear SVM C = 0.1'}, inplace = True)\n",
    "df_lsvm_test1.rename(columns = {'Linear SVM': 'C3 Linear SVM C = 0.1'}, inplace = True)\n",
    "df_lsvm_train2.rename(columns = {'Linear SVM': 'C3 Linear SVM C = 0.01'}, inplace = True)\n",
    "df_lsvm_test2.rename(columns = {'Linear SVM': 'C3 Linear SVM C = 0.01'}, inplace = True)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 594.915\n"
     ]
    }
   ],
   "source": [
    "# Before applying decision tree model to predict, \n",
    "# since the Decision Tree model's optimal parameter has not been searched, \n",
    "# I will use GridSearchCV to find the best parameter\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# set the parameter grid for max_depth\n",
    "param_grid = {'max_depth': np.arange(3,26)}\n",
    "clf_tree = GridSearchCV(DecisionTreeClassifier(),param_grid)\n",
    "clf_tree.fit(mnisttt.train.images, mnisttt.train.labels)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter for max_depth is 16 or 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to classify data using Decision Tree\n",
    "def clf_dtree(train_image, train_label, test_image, test_label, p):\n",
    "    clf = DecisionTreeClassifier(max_depth = p)\n",
    "    clf.fit(train_image, train_label)\n",
    "    train_pred = clf.predict(train_image)\n",
    "    test_pred = clf.predict(test_image)\n",
    "    df_train_temp = pd.DataFrame({'Label': train_label, 'Pred': train_pred})\n",
    "    df_test_temp = pd.DataFrame({'Label': test_label, 'Pred': test_pred})\n",
    "    # Correct -> 1, Wrong -> 0\n",
    "    df_train_temp['Decision tree'] = df_train_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    df_test_temp['Decision tree'] = df_test_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    return df_train_temp[['Decision tree']], df_test_temp[['Decision tree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 32.062\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Use Decision Tree to classify training and testing datasets with max_depth = 16\n",
    "df_dtree_train1, df_dtree_test1 = clf_dtree(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 16)\n",
    "\n",
    "# Use Decision Tree to classify training and testing datasets with max_depth = 10\n",
    "df_dtree_train2, df_dtree_test2 = clf_dtree(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 10)\n",
    "\n",
    "# rename the dataframes to include parameter\n",
    "df_dtree_train1.rename(columns = {'Decision tree': 'C4 Decision Tree max_depth = 16'}, inplace = True)\n",
    "df_dtree_test1.rename(columns = {'Decision tree': 'C4 Decision Tree max_depth = 16'}, inplace = True)\n",
    "df_dtree_train2.rename(columns = {'Decision tree': 'C4 Decision Tree max_depth = 10'}, inplace = True)\n",
    "df_dtree_test2.rename(columns = {'Decision tree': 'C4 Decision Tree max_depth = 10'}, inplace = True)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 487.623\n"
     ]
    }
   ],
   "source": [
    "# Before applying random forest model to predict, \n",
    "# since the Random Forest model's optimal parameter has not been searched, \n",
    "# I will use GridSearchCV to find the best parameter\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# set the parameter grid for max_depth\n",
    "param_grid = {'n_estimators': np.arange(10,51,10),'max_depth': np.arange(3,10)}\n",
    "clf_rdmforest = GridSearchCV(RandomForestClassifier(),param_grid)\n",
    "clf_rdmforest.fit(mnisttt.train.images, mnisttt.train.labels)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter set is: \n",
    "\n",
    "- max_depth = 9\n",
    "- n_estimators = 50\n",
    "\n",
    "The accuracy is presumed to continue increase with deeper depth and more estimators.\n",
    "\n",
    "The change in max_depth has larger effect on accuracy then change in n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to classify data using Random Forest\n",
    "def clf_rdmfst(train_image, train_label, test_image, test_label, p):\n",
    "    clf = RandomForestClassifier(n_estimators = 50, max_depth = p)\n",
    "    clf.fit(train_image, train_label)\n",
    "    train_pred = clf.predict(train_image)\n",
    "    test_pred = clf.predict(test_image)\n",
    "    df_train_temp = pd.DataFrame({'Label': train_label, 'Pred': train_pred})\n",
    "    df_test_temp = pd.DataFrame({'Label': test_label, 'Pred': test_pred})\n",
    "    # Correct -> 1, Wrong -> 0\n",
    "    df_train_temp['Random forest'] = df_train_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    df_test_temp['Random forest'] = df_test_temp[['Label','Pred']].apply(lambda x: 1 if x['Label'] == x['Pred'] else 0, axis = 1)\n",
    "    return df_train_temp[['Random forest']], df_test_temp[['Random forest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 31.375\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Use Random Forest to classify training and testing datasets with max_depth = 9\n",
    "df_rdmfst_train1, df_rdmfst_test1 = clf_rdmfst(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 9)\n",
    "\n",
    "# Use Random Forest to classify training and testing datasets with max_depth = 7\n",
    "df_rdmfst_train2, df_rdmfst_test2 = clf_rdmfst(mnisttt.train.images, mnisttt.train.labels, \n",
    "                                         mnisttt.test.images, mnisttt.test.labels, 7)\n",
    "# rename the dataframes to include parameter\n",
    "df_rdmfst_train1.rename(columns = {'Random forest': 'C5 Random Forest max_depth = 9'}, inplace = True)\n",
    "df_rdmfst_test1.rename(columns = {'Random forest': 'C5 Random Forest max_depth = 9'}, inplace = True)\n",
    "df_rdmfst_train2.rename(columns = {'Random forest': 'C5 Random Forest max_depth = 7'}, inplace = True)\n",
    "df_rdmfst_test2.rename(columns = {'Random forest': 'C5 Random Forest max_depth = 7'}, inplace = True)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all result together into a dataframe\n",
    "df_train_cw = pd.concat([df_p_train1, df_p_train2, df_logit_train1, df_logit_train2, \n",
    "                               df_lsvm_train1, df_lsvm_train2, df_dtree_train1, df_dtree_train2,\n",
    "                               df_rdmfst_train1, df_rdmfst_train2], axis = 1)\n",
    "\n",
    "df_test_cw = pd.concat([df_p_test1, df_p_test2, df_logit_test1, df_logit_test2, \n",
    "                               df_lsvm_test1, df_lsvm_test2, df_dtree_test1, df_dtree_test2,\n",
    "                               df_rdmfst_test1, df_rdmfst_test2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1 Perceptron n_iter = 75</th>\n",
       "      <th>C1 Perceptron n_iter = 150</th>\n",
       "      <th>C2 Logistic Regression C = 0.1</th>\n",
       "      <th>C2 Logistic Regression C = 0.01</th>\n",
       "      <th>C3 Linear SVM C = 0.1</th>\n",
       "      <th>C3 Linear SVM C = 0.01</th>\n",
       "      <th>C4 Decision Tree max_depth = 16</th>\n",
       "      <th>C4 Decision Tree max_depth = 10</th>\n",
       "      <th>C5 Random Forest max_depth = 9</th>\n",
       "      <th>C5 Random Forest max_depth = 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1 Perceptron n_iter = 75  C1 Perceptron n_iter = 150  \\\n",
       "0                          0                           0   \n",
       "1                          1                           1   \n",
       "2                          1                           1   \n",
       "3                          1                           1   \n",
       "4                          1                           1   \n",
       "\n",
       "   C2 Logistic Regression C = 0.1  C2 Logistic Regression C = 0.01  \\\n",
       "0                               1                                1   \n",
       "1                               1                                1   \n",
       "2                               1                                1   \n",
       "3                               1                                1   \n",
       "4                               1                                1   \n",
       "\n",
       "   C3 Linear SVM C = 0.1  C3 Linear SVM C = 0.01  \\\n",
       "0                      1                       1   \n",
       "1                      1                       1   \n",
       "2                      1                       1   \n",
       "3                      1                       1   \n",
       "4                      1                       1   \n",
       "\n",
       "   C4 Decision Tree max_depth = 16  C4 Decision Tree max_depth = 10  \\\n",
       "0                                1                                1   \n",
       "1                                1                                1   \n",
       "2                                1                                1   \n",
       "3                                1                                1   \n",
       "4                                1                                1   \n",
       "\n",
       "   C5 Random Forest max_depth = 9  C5 Random Forest max_depth = 7  \n",
       "0                               1                               1  \n",
       "1                               1                               1  \n",
       "2                               1                               1  \n",
       "3                               1                               1  \n",
       "4                               1                               1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the first 5 rows of training dataset result\n",
    "df_train_cw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save result to csv file\n",
    "df_train_cw.to_csv('train_correct_wrong.csv', index = True)\n",
    "df_test_cw.to_csv('test_correct_wrong.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set threshold and compute Easy / Hard label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read correct_wrong file\n",
    "df_train_cw = pd.read_csv('train_correct_wrong.csv', index_col = 0)\n",
    "df_test_cw = pd.read_csv('test_correct_wrong.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1 Perceptron n_iter = 75</th>\n",
       "      <th>C1 Perceptron n_iter = 150</th>\n",
       "      <th>C2 Logistic Regression C = 0.1</th>\n",
       "      <th>C2 Logistic Regression C = 0.01</th>\n",
       "      <th>C3 Linear SVM C = 0.1</th>\n",
       "      <th>C3 Linear SVM C = 0.01</th>\n",
       "      <th>C4 Decision Tree max_depth = 16</th>\n",
       "      <th>C4 Decision Tree max_depth = 10</th>\n",
       "      <th>C5 Random Forest max_depth = 9</th>\n",
       "      <th>C5 Random Forest max_depth = 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1 Perceptron n_iter = 75  C1 Perceptron n_iter = 150  \\\n",
       "0                          0                           0   \n",
       "1                          1                           1   \n",
       "2                          1                           1   \n",
       "3                          1                           1   \n",
       "4                          1                           1   \n",
       "\n",
       "   C2 Logistic Regression C = 0.1  C2 Logistic Regression C = 0.01  \\\n",
       "0                               1                                1   \n",
       "1                               1                                1   \n",
       "2                               1                                1   \n",
       "3                               1                                1   \n",
       "4                               1                                1   \n",
       "\n",
       "   C3 Linear SVM C = 0.1  C3 Linear SVM C = 0.01  \\\n",
       "0                      1                       1   \n",
       "1                      1                       1   \n",
       "2                      1                       1   \n",
       "3                      1                       1   \n",
       "4                      1                       1   \n",
       "\n",
       "   C4 Decision Tree max_depth = 16  C4 Decision Tree max_depth = 10  \\\n",
       "0                                1                                1   \n",
       "1                                1                                1   \n",
       "2                                1                                1   \n",
       "3                                1                                1   \n",
       "4                                1                                1   \n",
       "\n",
       "   C5 Random Forest max_depth = 9  C5 Random Forest max_depth = 7  \n",
       "0                               1                               1  \n",
       "1                               1                               1  \n",
       "2                               1                               1  \n",
       "3                               1                               1  \n",
       "4                               1                               1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correct_wrong dataframe\n",
    "df_train_cw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set default threshold to be 50%\n",
    "# Easy -> 0, Hard -> 1\n",
    "df_train_cw_50 = df_train_cw.apply(lambda x: 0 if np.average(x) >= 0.5 else 1, axis = 1)\n",
    "df_test_cw_50 = df_test_cw.apply(lambda x: 0 if np.average(x) >= 0.5 else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    56171\n",
      "1     3829\n",
      "dtype: int64\n",
      "0    9272\n",
      "1     728\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of easy and hard images\n",
    "print(df_train_cw_50.value_counts())\n",
    "print(df_test_cw_50.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the array of easy/hard label\n",
    "eh_train_label_50 = df_train_cw_50.values\n",
    "eh_test_label_50 = df_test_cw_50.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Easy / Hard Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since any classification model can be used to classify the easy / hard label, logistic regression is chosen for this step.\n",
    "\n",
    "To achieve better accuracy, gridsearchCV is used in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 598.904\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# set the parameter grid for C\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 5]}\n",
    "# use stratified 3-fold cross validation to tune the model\n",
    "# use accuracy as scoring parameter\n",
    "clf_eh_grid = GridSearchCV(LogisticRegression(penalty= 'l2', solver='newton-cg'),param_grid, scoring = 'accuracy', cv = 3)\n",
    "clf_eh_grid.fit(mnisttt.train.images, eh_train_label_50)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.93618, std: 0.00002, params: {'C': 0.0001},\n",
       " mean: 0.93618, std: 0.00002, params: {'C': 0.001},\n",
       " mean: 0.93615, std: 0.00007, params: {'C': 0.01},\n",
       " mean: 0.93612, std: 0.00019, params: {'C': 0.1},\n",
       " mean: 0.93572, std: 0.00065, params: {'C': 1},\n",
       " mean: 0.93517, std: 0.00073, params: {'C': 5}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_eh_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal tuned Logistic Regression model:\n",
    "\n",
    "- parameter: C = 0.001\n",
    "\n",
    "- average accuracy = 93.618%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92720000000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test labels and get accuracy\n",
    "clf_eh_grid.score(mnisttt.test.images, eh_test_label_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is 92.72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Easy Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Easy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training easy image data\n",
    "train_image_easy = pd.DataFrame(mnisttt.train.images)\n",
    "train_image_easy['eh'] = eh_train_label_50\n",
    "train_image_easy = train_image_easy[train_image_easy['eh'] == 0]\n",
    "train_image_easy.drop(['eh'], axis = 1, inplace = True)\n",
    "\n",
    "# split testing easy image data\n",
    "test_image_easy = pd.DataFrame(mnisttt.test.images)\n",
    "test_image_easy['eh'] = eh_test_label_50\n",
    "test_image_easy = test_image_easy[test_image_easy['eh'] == 0]\n",
    "test_image_easy.drop(['eh'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56171, 784)\n",
      "(9272, 784)\n"
     ]
    }
   ],
   "source": [
    "# check training and testing easy image dataset shape\n",
    "print(train_image_easy.shape)\n",
    "print(test_image_easy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training easy label data\n",
    "train_label_easy = pd.DataFrame(mnisttt.train.labels)\n",
    "train_label_easy['eh'] = eh_train_label_50\n",
    "train_label_easy = train_label_easy[train_label_easy['eh'] == 0]\n",
    "train_label_easy.drop(['eh'], axis = 1, inplace = True)\n",
    "\n",
    "# split testing easy label data\n",
    "test_label_easy = pd.DataFrame(mnisttt.test.labels)\n",
    "test_label_easy['eh'] = eh_test_label_50\n",
    "test_label_easy = test_label_easy[test_label_easy['eh'] == 0]\n",
    "test_label_easy.drop(['eh'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56171, 1)\n",
      "(9272, 1)\n"
     ]
    }
   ],
   "source": [
    "# check training and testing easy label dataset shape\n",
    "print(train_label_easy.shape)\n",
    "print(test_label_easy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple Classifier for Easy Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the simple classifier, the model with best accuracy is Radial SVM (C = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 104.763\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# fit easy data to radial svm model\n",
    "clf_easy = SVC(C = 50, kernel = 'rbf', degree = 3, gamma = 'auto')\n",
    "clf_easy.fit(train_image_easy, train_label_easy)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99525452976704054"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the accuracy of the easy model on test dataset\n",
    "clf_easy.score(test_image_easy, test_label_easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Hard Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Hard Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load OneHotEncode dataset\n",
    "mnisttt_one_hot = input_data.read_data_sets(\".\", one_hot=True, validation_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training hard image data\n",
    "train_image_hard = pd.DataFrame(mnisttt_one_hot.train.images)\n",
    "train_image_hard['eh'] = eh_train_label_50\n",
    "train_image_hard = train_image_hard[train_image_hard['eh'] == 1]\n",
    "train_image_hard.drop(['eh'], axis = 1, inplace = True)\n",
    "\n",
    "# split testing hard image data\n",
    "test_image_hard = pd.DataFrame(mnisttt_one_hot.test.images)\n",
    "test_image_hard['eh'] = eh_test_label_50\n",
    "test_image_hard = test_image_hard[test_image_hard['eh'] == 1]\n",
    "test_image_hard.drop(['eh'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3829, 784)\n",
      "(728, 784)\n"
     ]
    }
   ],
   "source": [
    "# check training and testing hard image dataset shape\n",
    "print(train_image_hard.shape)\n",
    "print(test_image_hard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training hard label data\n",
    "train_label_hard = pd.DataFrame(mnisttt_one_hot.train.labels)\n",
    "train_label_hard['eh'] = eh_train_label_50\n",
    "train_label_hard = train_label_hard[train_label_hard['eh'] == 1]\n",
    "train_label_hard.drop(['eh'], axis = 1, inplace = True)\n",
    "\n",
    "# split testing hard label data\n",
    "test_label_hard = pd.DataFrame(mnisttt_one_hot.test.labels)\n",
    "test_label_hard['eh'] = eh_test_label_50\n",
    "test_label_hard = test_label_hard[test_label_hard['eh'] == 1]\n",
    "test_label_hard.drop(['eh'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3829, 10)\n",
      "(728, 10)\n"
     ]
    }
   ],
   "source": [
    "# check training and testing hard label dataset shape\n",
    "print(train_label_hard.shape)\n",
    "print(test_label_hard.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Classifier for Hard Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use tensorflow to construct CNN Classifier\n",
    "# set parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "k = 2\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set network parameters\n",
    "nodes_input = 784 # number of input nodes: MNIST image input is 784 pixels (image size is 28 x 28 pixels)\n",
    "nodes_classes = 10 # number of output nodes: network output is digits 0-9\n",
    "dropout = 0.80 # probability to keep units, used to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(img, w, s, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides = [1, s, s, 1], padding = 'SAME'), b))\n",
    "    \n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to construct the CNN model\n",
    "def cnn_clf(learn, iters, batch, display_step, ss, kk):\n",
    "    \n",
    "    # tensorflow graph input\n",
    "    x = tf.placeholder(tf.float32, [None, nodes_input]) \n",
    "    y = tf.placeholder('float', [None, nodes_classes]) \n",
    "    keep_probability = tf.placeholder(tf.float32)\n",
    "    # store weight and bias for each layer\n",
    "\n",
    "    # 5x5 convolution layer 1, 1 input, 32 outputs (feature maps)\n",
    "    weights_c1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
    "    bias_c1 = tf.Variable(tf.random_normal([32]))\n",
    "    \n",
    "    # 5x5 convolution layer 2, 32 inputs, 64 outputs (feature maps)\n",
    "    weights_c2 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
    "    bias_c2 = tf.Variable(tf.random_normal([64]))\n",
    "    \n",
    "    # fully connected layer, 7*7*64 inputs, 1024 outputs\n",
    "    weights_d1 = tf.Variable(tf.random_normal([7 * 7 * 64, 1024]))\n",
    "    \n",
    "    # class prediction layer, 1024 inputs, 10 outputs\n",
    "    weights_out = tf.Variable(tf.random_normal([1024, nodes_classes]))\n",
    "    bias_d1 = tf.Variable(tf.random_normal([1024]))\n",
    "    bias_out = tf.Variable(tf.random_normal([nodes_classes]))\n",
    "    \n",
    "    # transform 4D input images to a tensor\n",
    "    _X = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "    \n",
    "    # construct convolution layer 1\n",
    "    conv1 = conv2d(_X, weights_c1, s, bias_c1)\n",
    "    # apply max pooling\n",
    "    conv1 = max_pool(conv1, k = kk)\n",
    "    # apply dropout\n",
    "    conv1 = tf.nn.dropout(conv1, keep_probability)\n",
    "    \n",
    "    # construct convolution layer 2\n",
    "    conv2 = conv2d(conv1, weights_c2, s, bias_c2)\n",
    "    # apply max pooling\n",
    "    conv2 = max_pool(conv2, k = kk)\n",
    "    # apply dropout\n",
    "    conv2 = tf.nn.dropout(conv2, keep_probability)\n",
    "    \n",
    "    # construct fully connected layer\n",
    "    # reshape conv2 output to fit dense layer input\n",
    "    dense1 = tf.reshape(conv2, [-1, weights_d1.get_shape().as_list()[0]])\n",
    "    # relu activation\n",
    "    dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, weights_d1), bias_d1))\n",
    "    # apply dropout\n",
    "    dense1 = tf.nn.dropout(dense1, keep_probability)\n",
    "    \n",
    "    # construct prediction output layer\n",
    "    prediction = tf.add(tf.matmul(dense1, weights_out), bias_out)\n",
    "    \n",
    "    # cost function\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "    \n",
    "    # optimizer (adam optimizer controls the learning rate, could also use gradient descent optimizer)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learn).minimize(cost)\n",
    "    \n",
    "    # evaluate model\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # initialize variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    # launch graph\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "    \n",
    "        step = 1\n",
    "        # train until reach max iterations\n",
    "        while step * batch < iters:\n",
    "            batch_xs, batch_ys = mnisttt.train.next_batch(batch)\n",
    "            # fit training using batch data\n",
    "            sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys, keep_probability: dropout})\n",
    "            if step % display_step == 0:\n",
    "                # calculate batch accuracy\n",
    "                acc = sess.run(accuracy, feed_dict = {x: batch_xs, y: batch_ys, keep_probability: 1.})\n",
    "                # calculate batch loss\n",
    "                loss = sess.run(cost, feed_dict = {x: batch_xs, y: batch_ys, keep_probability: 1.})\n",
    "                # print('Iter ' + str(step * batch) + ', Minibatch Loss = ' + '{:.6f}'.format(loss) + ', Training Accuracy = ' + '{:.5f}'.format(acc))\n",
    "            step += 1\n",
    "    \n",
    "        print('Optimization finished')\n",
    "        # calculate accuracy\n",
    "        print('Testing Accuracy:', sess.run(accuracy, feed_dict = {x: mnisttt.test.images[:256], y: mnisttt.test.labels[:256], keep_probability: 1.}))\n",
    "    \n",
    "    stop = timeit.default_timer()    \n",
    "    print('Running time: %.3f' % (stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-65-7cb30b5b4b67>:65: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (128,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-f66904bb2ba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-7cb30b5b4b67>\u001b[0m in \u001b[0;36mcnn_clf\u001b[0;34m(learn, iters, batch, display_step, ss, kk)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnisttt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# fit training using batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# calculate batch accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Michael/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Michael/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    962\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "cnn_clf(learning_rate, training_iters, batch_size, display_step, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
